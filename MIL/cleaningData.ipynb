{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import pydicom\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom as DCM\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MnistBags(data_utils.Dataset):\n",
    "#     def __init__(self, target_number, mean_bag_length, var_bag_length, num_bag=250, seed=1, train=True):\n",
    "#         self.target_number = target_number\n",
    "#         self.mean_bag_length = mean_bag_length\n",
    "#         self.var_bag_length = var_bag_length\n",
    "#         self.num_bag = num_bag\n",
    "#         self.train = train\n",
    "\n",
    "#         self.r = np.random.RandomState(seed)\n",
    "\n",
    "#         self.num_in_train = 60000\n",
    "#         self.num_in_test = 10000\n",
    "\n",
    "#         if self.train:\n",
    "#             self.train_bags_list, self.train_labels_list = self._create_bags()\n",
    "#         else:\n",
    "#             self.test_bags_list, self.test_labels_list = self._create_bags()\n",
    "\n",
    "#     def _create_bags(self):\n",
    "#         if self.train:\n",
    "#             loader = data_utils.DataLoader(datasets.MNIST('../datasets',\n",
    "#                                                           train=True,\n",
    "#                                                           download=True,\n",
    "#                                                           transform=transforms.Compose([\n",
    "#                                                               transforms.ToTensor(),\n",
    "#                                                               transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "#                                            batch_size=self.num_in_train,\n",
    "#                                            shuffle=False)\n",
    "#         else:\n",
    "#             loader = data_utils.DataLoader(datasets.MNIST('../datasets',\n",
    "#                                                           train=False,\n",
    "#                                                           download=True,\n",
    "#                                                           transform=transforms.Compose([\n",
    "#                                                               transforms.ToTensor(),\n",
    "#                                                               transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "#                                            batch_size=self.num_in_test,\n",
    "#                                            shuffle=False)\n",
    "\n",
    "#         for (batch_data, batch_labels) in loader:\n",
    "#             all_imgs = batch_data\n",
    "#             all_labels = batch_labels\n",
    "        \n",
    "        \n",
    "#         bags_list = []\n",
    "#         labels_list = []\n",
    "\n",
    "#         for i in range(self.num_bag):\n",
    "#             bag_length = np.int(self.r.normal(self.mean_bag_length, self.var_bag_length, 1))\n",
    "#             if bag_length < 1:\n",
    "#                 bag_length = 1\n",
    "\n",
    "#             if self.train:\n",
    "#                 indices = torch.LongTensor(self.r.randint(0, self.num_in_train, bag_length))\n",
    "#             else:\n",
    "#                 indices = torch.LongTensor(self.r.randint(0, self.num_in_test, bag_length))\n",
    "\n",
    "#             labels_in_bag = all_labels[indices]\n",
    "#             labels_in_bag = labels_in_bag == self.target_number\n",
    "\n",
    "#             bags_list.append(all_imgs[indices])\n",
    "#             labels_list.append(labels_in_bag)\n",
    "\n",
    "#         return bags_list, labels_list\n",
    "\n",
    "#     def __len__(self):\n",
    "#         if self.train:\n",
    "#             return len(self.train_labels_list)\n",
    "#         else:\n",
    "#             return len(self.test_labels_list)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         if self.train:\n",
    "#             bag = self.train_bags_list[index]\n",
    "#             label = [max(self.train_labels_list[index]), self.train_labels_list[index]]\n",
    "#         else:\n",
    "#             bag = self.test_bags_list[index]\n",
    "#             label = [max(self.test_labels_list[index]), self.test_labels_list[index]]\n",
    "\n",
    "#         return bag, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/himanshu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainFrame(homedir):\n",
    "    \n",
    "    train_mass_csv = pd.read_csv(homedir+\"/CuratedDDSM/Train/mass_case_description_train_set.csv\")\n",
    "    train_calc_csv = pd.read_csv(homedir+\"/CuratedDDSM/Train/calc_case_description_train_set.csv\")\n",
    "    train_calc_csv = train_calc_csv.rename(columns={'breast density': 'breast_density'})\n",
    "    train_calc_csv['image file path'] = 'Calc/CBIS-DDSM/'+ train_calc_csv['image file path']\n",
    "    train_calc_csv['ROI mask file path'] ='CalcROI/CBIS-DDSM/' + train_calc_csv['ROI mask file path']\n",
    "    train_calc_csv['cropped image file path'] ='CalcROI/CBIS-DDSM/' + train_calc_csv['cropped image file path']\n",
    "    train_mass_csv['image file path'] = 'Mass/CBIS-DDSM/' + train_mass_csv['image file path']\n",
    "    train_mass_csv['ROI mask file path'] ='MassROI/CBIS-DDSM/' + train_mass_csv['ROI mask file path']\n",
    "    train_mass_csv['cropped image file path'] ='MassROI/CBIS-DDSM/'+ train_mass_csv['cropped image file path']\n",
    "    common_col = list(set(train_calc_csv.columns) & set(train_mass_csv.columns))\n",
    "    train = pd.concat([train_mass_csv[common_col],train_calc_csv[common_col]], ignore_index=True,sort='False')\n",
    "    #train = train_mass_csv\n",
    "    train['image file path'] = homedir+'/CuratedDDSM/Train/'+train['image file path'] \n",
    "    train['ROI mask file path'] = homedir+'/CuratedDDSM/Train/'+train['ROI mask file path']\n",
    "    train['cropped image file path'] = homedir+'/CuratedDDSM/Train/'+train['cropped image file path']\n",
    "    train=train[train.pathology!='BENIGN_WITHOUT_CALLBACK']\n",
    "    train['pathology_class'] = LabelEncoder().fit_transform(train['pathology'])\n",
    "    train =  pd.concat([train,pd.get_dummies(train['pathology'])],axis=1)\n",
    "    \n",
    "    ''' proper ROI mask present check'''\n",
    "    \n",
    "    train['image file path']=train['image file path'].str.replace('\\n',\"\")\n",
    "    train['ROI mask file path']=train['ROI mask file path'].str.replace('\\n',\"\")\n",
    "    train['cropped image file path']=train['cropped image file path'].str.replace('\\n','')\n",
    "    \n",
    "    notfound = []\n",
    "    for index, row in train.iterrows():\n",
    "        if(os.path.isfile(row['cropped image file path'])==False\n",
    "           or os.path.isfile(row['ROI mask file path'])==False or os.path.isfile(row['image file path'])==False):\n",
    "            notfound.append(index)\n",
    "    \n",
    "    train.drop(train.index[notfound], inplace=True)\n",
    "    \n",
    "    train = train.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = createTrainFrame('/media/erh/BEFCFF6AFCFF1B7B/dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplepath =  train['image file path'][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img  = DCM.dcmread(samplepath).pixel_array\n",
    "img.shape == img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "okcount=0\n",
    "count=0\n",
    "deleteIndex = []\n",
    "for index, row in train.iterrows():\n",
    "    mask = DCM.dcmread(row['ROI mask file path']).pixel_array \n",
    "    crop = DCM.dcmread(row['cropped image file path']).pixel_array\n",
    "    img = DCM.dcmread(row['image file path']).pixel_array\n",
    "    if(img.shape==mask.shape):\n",
    "        okcount=okcount+1\n",
    "    else:\n",
    "        if(img.shape==crop.shape):\n",
    "            train.loc[index,['cropped image file path','ROI mask file path']] = train.loc[index,['ROI mask file path','cropped image file path']].values\n",
    "        else:\n",
    "            deleteIndex.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5386, 3601) (4686, 3133) (275, 318)\n",
      "(5386, 3466) (4686, 3016) (267, 346)\n",
      "(5386, 3391) (4686, 2951) (344, 319)\n",
      "(5386, 3436) (4686, 2990) (306, 337)\n",
      "(5386, 3691) (4686, 3212) (539, 698)\n",
      "(5221, 3391) (4543, 2951) (428, 316)\n",
      "(5296, 3061) (4608, 2664) (369, 440)\n",
      "(5296, 3436) (4608, 2990) (374, 399)\n",
      "(5026, 2131) (4373, 1854) (517, 553)\n",
      "(4966, 3061) (4321, 2664) (304, 318)\n",
      "(5326, 3421) (4634, 2977) (363, 445)\n",
      "(5356, 2581) (4660, 2246) (350, 356)\n",
      "(5386, 3061) (4686, 2664) (347, 388)\n",
      "(5296, 2566) (4608, 2233) (420, 357)\n",
      "(5386, 2836) (4686, 2468) (372, 360)\n",
      "(5011, 2596) (4360, 2259) (554, 563)\n",
      "(5116, 2371) (4451, 2063) (431, 428)\n",
      "(5221, 3121) (4543, 2716) (385, 374)\n",
      "(5386, 3436) (4686, 2990) (535, 500)\n",
      "(5356, 2851) (4660, 2481) (313, 318)\n",
      "(5266, 2761) (4582, 2403) (337, 340)\n"
     ]
    }
   ],
   "source": [
    "okcount=0\n",
    "count=0\n",
    "for index, row in train.iterrows():\n",
    "    mask = DCM.dcmread(row['ROI mask file path']).pixel_array \n",
    "    crop = DCM.dcmread(row['cropped image file path']).pixel_array\n",
    "    img = DCM.dcmread(row['image file path']).pixel_array\n",
    "    if(img.shape==mask.shape):\n",
    "        okcount=okcount+1\n",
    "    else:\n",
    "        #train.loc[index,['cropped image file path','ROI mask file path']] = train.loc[index,['ROI mask file path','cropped image file path']].values\n",
    "        print(img.shape,mask.shape,crop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "notfound=[]\n",
    "for index, row in train.iterrows():\n",
    "    if(os.path.isfile(row['cropped image file path'])):\n",
    "        notfound.append(index)\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ROI mask file path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(train)):\n",
    "    \"\"\" Clean the data,\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
