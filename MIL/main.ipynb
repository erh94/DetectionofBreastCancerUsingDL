{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from customDataset import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Device Selection\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 200\n",
    "batch_size = 1\n",
    "learning_rate = 0.01\n",
    "num_classes = 2\n",
    "patch_size =H=W=512\n",
    "\n",
    "\n",
    "def pause(strg):\n",
    "    if(strg!=''):\n",
    "        print('Reached at {}, Press any key to continue'.format(strg))\n",
    "    else:\n",
    "        print('Paused, Press any to continue')\n",
    "    input()\n",
    "    return\n",
    "\n",
    "\n",
    "homedir = str(Path.home())\n",
    "print(homedir)\n",
    "\n",
    "# train_df = CDDSM.createTrainFrame(homedir)\n",
    "# test_df = CDDSM.createTestFrame(homedir)\n",
    "# mammogram_dir = '/home/himanshu/CuratedDDSM/'\n",
    "# train_file = mammogram_dir+'train.csv'\n",
    "# test_file = mammogram_dir+'test.csv'\n",
    "# train_df.to_csv(train_file)\n",
    "# test_df.to_csv(test_file)\n",
    "\n",
    "# classes = ('BENIGN', 'BENIGN_WITHOUT_CALLBACK', 'MALIGNANT')\n",
    "# Created a cleaned data file in train.csv and test.csv\n",
    "\n",
    "train_file = 'train.csv'\n",
    "test_file = 'test.csv'\n",
    "\n",
    "# Making of CBIS-DDSM Dataset (train,val,test)\n",
    "\n",
    "dataset =  MammographyDataset(train_file,homedir,patch_size,'train')\n",
    "test_dataset = MammographyDataset(test_file,homedir,patch_size,'test')\n",
    "\n",
    "train_dataset , val_dataset = trainValSplit(dataset,val_share=0.98)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Length of each Dataset\n",
    "\n",
    "numberOfTrainData = train_dataset.__len__()\n",
    "numberOfValData = val_dataset.__len__()\n",
    "numberOfTestData =  test_dataset.__len__()\n",
    "\n",
    "total_step=len(train_loader)\n",
    "\n",
    "print('Size of training dataset {}'.format(numberOfTrainData))\n",
    "print('Size of Validation dataset {}'.format(numberOfValData))\n",
    "print('Size of testing dataset {}'.format(numberOfTestData))\n",
    "print('No. of Epochs: {}\\n Batch size: {}\\n Learning_rate : {}\\n Image size {}*{}\\n Step {}'\n",
    "        .format(num_epochs,batch_size,learning_rate,H,W,total_step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking images in each dataset by making grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainloader = train_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.rcParams[\"figure.figsize\"] = [12,18]\n",
    "    plt.imshow((np.transpose(npimg, (1, 2, 0))).astype(np.uint8))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "batch,bag_label,bag_img = dataiter.next()\n",
    "\n",
    "images =  batch[0]\n",
    "labels = bag_label[0]\n",
    "print(labels.shape)\n",
    "print(labels)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images,nrow=7))\n",
    "# # print labels\n",
    "# print(' '.join('%5s' % labels[j] for j in range(21)))\n",
    "\n",
    "# bag_label\n",
    "\n",
    "# newimg = bag_img.numpy()\n",
    "# newimg.shape\n",
    "# alpha = np.transpose(newimg,(1,2,0))\n",
    "# alpha=alpha.squeeze(2)\n",
    "\n",
    "#  plt.imshow(alpha,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilImage = torchvision.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output= pilImage(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# val Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = val_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "# images, labels = dataiter.next()\n",
    "batch,bag_label,bag_img = dataiter.next()\n",
    "\n",
    "images =  batch[0]\n",
    "labels = batch_labels[0] \n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images,nrow=7))\n",
    "# # print labels\n",
    "# print(' '.join('%5s' % labels[j] for j in range(21)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# test Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(images,labels,new) in enumerate(train_loader):\n",
    "    print(i,images.shape,labels.shape,new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter=iter(train_loader)\n",
    "batch,bag_label,bag_img = dataiter?\n",
    "print(batch.shape,bag_label.shape,bag_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = test_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "batch,bag_label,bag_img = dataiter.next()\n",
    "\n",
    "images =  batch[0]\n",
    "labels = bag_label[0] \n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images,nrow=7))\n",
    "# # print labels\n",
    "# print(' '.join('%5s' % labels[j] for j in range(21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class myCustomModel(torch.nn.Module):\n",
    "    def __init__(self,pretrainedModel):\n",
    "        super(myCustomModel,self).__init__()\n",
    "        \n",
    "        self.layer0 = nn.Sequential()\n",
    "        self.layer0.add_module('conv0',nn.Conv2d(1,3,kernel_size=9,stride=1,padding=0,dilation=8))\n",
    "        self.layer0.add_module('relu0',nn.ReLU())\n",
    "        self.layer0.add_module('maxpool',nn.MaxPool2d(kernel_size=2))\n",
    "        self.layer1 = nn.Sequential()\n",
    "        self.layer1.add_module('pretrained',pretrainedModel)\n",
    "        self.fc = nn.Linear(in_features=512,out_features=2)\n",
    "    def forward(self,x):\n",
    "        x = self.layer0(x)\n",
    "        features = self.layer1(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        x =  self.fc(features)\n",
    "        return x, self.prediction(x)\n",
    "    def prediction(self,x):\n",
    "        predBag=1-torch.prod(torch.exp(torch.mul(F.relu(x),-0.5)),dim=0)\n",
    "        return predBag\n",
    "\n",
    "def getCustomPretrained(model):\n",
    "    return myCustomModel(model)\n",
    "    \n",
    "\n",
    "class MIL_loss(torch.nn.Module):\n",
    "    ''' MIL Loss Layer'''\n",
    "    def __init__(self,lamda):\n",
    "        super(MIL_loss, self).__init__()\n",
    "        self.lamda = lamda\n",
    "        \n",
    "    def forward(self,scores,labels):\n",
    "        ''' lamda is postive constant,\n",
    "        to convert scores(h_i) into probability'''\n",
    "        sum_scores = -torch.sum(torch.mul(F.relu(scores),self.lamda),dim=0)\n",
    "        loss = -torch.dot(1-labels.float(),sum_scores.float())\n",
    "        return loss\n",
    "\n",
    "# parameters with parameters requires grad is True\n",
    "# for p in resnet18.parameters():\n",
    "#     print(p.requires_grad)\n",
    "\n",
    "# model = B.getModel(3).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIL Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(21, 1,512 ,512)\n",
    "x=x.to(device)\n",
    "features,y = model(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = torch.autograd.Variable(torch.tensor([0])).cuda()\n",
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = y\n",
    "# class_label = torch.autograd.Variable(torch.tensor([1,0])).cuda()\n",
    "# scores =  torch.autograd.Variable(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.17 * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)\n",
    "scores =  F.relu(scores)\n",
    "lamda = 0.5\n",
    "scores =  torch.mul(scores,lamda)\n",
    "print(scores)\n",
    "prob = torch.exp(-scores)\n",
    "prob_of_bag_not_class = torch.prod(prob,dim=0)\n",
    "print(prob_of_bag_not_class)\n",
    "neglogbag = - torch.log(prob_of_bag_not_class)\n",
    "print(neglogbag)\n",
    "print(labels)\n",
    "torch.dot(1-labels.float(),neglogbag.float())\n",
    "prob_of_bag_class = 1 - prob_of_bag_not_class\n",
    "sum_scores =-torch.sum(scores,dim=0)\n",
    "print(sum_scores)\n",
    "print(prob_of_bag_class)\n",
    "-torch.dot(1-labels.float(),sum_scores.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = y\n",
    "# class_label = torch.autograd.Variable(torch.tensor([1,0])).cuda()\n",
    "# scores =  torch.autograd.Variable(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Go in main----------------#\n",
    "\n",
    "import torchvision.models as models\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "# -----------Uncomment the below two lines to freeze the weights--------------------#\n",
    "# for param in resnet.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# model = B.getModel(3).to(device)\n",
    "model=getCustomPretrained(resnet)\n",
    "model=model.to(device)\n",
    "\n",
    "# store best prediction in one epoch\n",
    "\n",
    "best_prec = 0\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = MIL_loss(0.5)\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images= batch[0]\n",
    "labels=bag_label[0]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(21,1,512,512)\n",
    "x=images.to(device)\n",
    "a,b=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.dtype)\n",
    "print(bag_img.shape)\n",
    "print(bag_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,y=model(images.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=y\n",
    "lamda=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_scores = torch.sum(torch.mul(F.relu(scores),lamda),dim=0)\n",
    "print(sum_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -torch.dot(1-bag_label.float(),sum_scores.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "print(labels)\n",
    "print(bag_label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "scores,pred = model(images)\n",
    "loss = criterion(scores,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss.item(),pred)\n",
    "print(loss.dtype)\n",
    "print(pred.dtype)\n",
    "print(labels.dtype)\n",
    "\n",
    "# 1-torch.prod(torch.exp(torch.mul(F.relu(scores),-0.5)),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter('runs',comment=\"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state,is_best,filename='./models/checkpoint.pth.tar'):\n",
    "        torch.save(state,filename)\n",
    "        if is_best:\n",
    "            shutil.copyfile(filename,'./models/model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader,model,criterion,optimizer,epoch,writer):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    avgaccu =  AverageMeter()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    end = time.time()\n",
    "    for i,(batch,bag_label,_) in enumerate(train_loader):\n",
    "        data_time.update(time.time()-end)\n",
    "        images = batch[0].to(device)\n",
    "        labels = bag_label[0].to(device)\n",
    "        \n",
    "        scores,pred = model(images)\n",
    "        loss = criterion(scores,labels)\n",
    "        \n",
    "        # top-k ? accuaracy \n",
    "        # for now evaluating normal accuracy\n",
    "        acc = accuracy(pred,labels)\n",
    "        \n",
    "        #loss.item() to get the loss value from loss tensor\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        avgaccu.update(acc,images.size(0))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "              'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "              'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "              'Accuracy {acc.val:.4f} ({acc.avg:.4f})\\t'.format(\n",
    "               epoch, i, len(train_loader), batch_time=batch_time,\n",
    "               data_time=data_time, loss=losses, acc=avgaccu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    avgaccu =  AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (batch, bag_label,_) in enumerate(val_loader):\n",
    "            input= batch[0].to(device)\n",
    "            target = bag_label[0].to(device)\n",
    "            \n",
    "            # compute output\n",
    "            scores,pred = model(input)\n",
    "            loss = criterion(scores, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc= accuracy(pred, target)\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            avgaccu.update(acc,input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            print('Validation: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Acc {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,acc=avgaccu))\n",
    "\n",
    "        print(' * Acc {acc.avg:.3f}'\n",
    "              .format(acc=avgaccu))\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred,true):\n",
    "    with torch.no_grad():\n",
    "        batch_size =  target.size(0)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total = target.size(0)\n",
    "        correct = (predicted == target).sum().item()\n",
    "        acc = correct/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader,model):\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MILloss(prediction,labels):\n",
    "    # score will be calculated from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_freq=10\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    adjust_learning_rate(optimizer,epoch,learning_rate)\n",
    "    \n",
    "    \n",
    "    train(train_loader,model,criterion,optimizer,epoch,writer)\n",
    "    \n",
    "    pause('')\n",
    "    \n",
    "    acc =  validate(val_loader,model,criterion)\n",
    "    \n",
    "    \n",
    "    \n",
    "    is_best = acc > best_acc\n",
    "    \n",
    "    best_acc = max(acc,best_acc)\n",
    "    \n",
    "    \n",
    "    #saving the checkpoint if is_best is True\n",
    "    save_checkpoint({\n",
    "        'epoch':epoch+1,\n",
    "        'state_dict':model.state_dict(),\n",
    "        'best_acc':best_acc,\n",
    "        'optimizer':optimizer.state_dict(),\n",
    "    },is_best)\n",
    "    \n",
    "test(test_loader=test_loader,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
